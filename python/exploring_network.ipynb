{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring and analysing the network data in Python\n",
    "\n",
    "## Part 0: Overview\n",
    "\n",
    "### The data\n",
    "For this part of the workshop, you will work with the data export you performed at the end of the Gephi part of the workshop.\n",
    "If you did not manage to make a good export, or if you wish to take this part , you can use the file located at `files/example_gephi_export.csv`\n",
    "\n",
    "### Prior experience with Python\n",
    "This part of the workshop presumes **no** knowledge of Python. Depending on your experience, try to read the materials below as a book, change parts of the code to your liking, or write whole new analyses. \n",
    "\n",
    "### Working with Jupyter Python Notebooks\n",
    "If you are not used to working with Python Notebooks, note that it is easiest to run the notebooks through Google Colab. The instructors will explain how to do so.\n",
    "If you wish to run the Notebooks on your local machine, you will need to install a few packages. These are listed in `python/requirements.in`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Opening and exploring the Gephi export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the Pandas package for much of this workshop\n",
    "# you do not need to understand everything that is going on, as long as you are able to follow the steps in a general sense\n",
    "import pandas as pd\n",
    "\n",
    "# read the nodes table\n",
    "nodes = pd.read_csv('../files/example_gephi_export.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47404 entries, 0 to 47403\n",
      "Data columns (total 12 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Id                                     47404 non-null  object \n",
      " 1   Label                                  46760 non-null  object \n",
      " 2   author.description                     36612 non-null  object \n",
      " 3   author.public_metrics.followers_count  46760 non-null  float64\n",
      " 4   author.public_metrics.following_count  46760 non-null  float64\n",
      " 5   indegree                               47404 non-null  int64  \n",
      " 6   outdegree                              47404 non-null  int64  \n",
      " 7   Degree                                 47404 non-null  int64  \n",
      " 8   weighted indegree                      47404 non-null  int64  \n",
      " 9   weighted outdegree                     47404 non-null  int64  \n",
      " 10  Weighted Degree                        47404 non-null  int64  \n",
      " 11  modularity_class                       47404 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(3)\n",
      "memory usage: 4.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# display some information about the data\n",
    "# do you know what each column means? If not, go back to Gephi and try to figure it out\n",
    "print(nodes.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using .head(), we can display the first N rows (default=5)\n",
    "print(nodes.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect a column\n",
    "print(nodes['author.description'].head(5))\n",
    "\n",
    "# display the full value of the author.description for the first row\n",
    "print(nodes.iloc[0]['author.description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Extracting information\n",
    "Inspecting a single user descirption reveals an interesting detail. Hashtags (e.g. #IamAChristian) are a vital part of Twitter/X's vocabulary. \n",
    "Extracting them from the descriptions will enable easier comparison with other users.\n",
    "To extract the hashtags, we will use a *Regular Expression*: a pattern that defines part of a text that we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Python's built-in Regular Expressions package\n",
    "import re\n",
    "\n",
    "hashtag_pattern = r'\\#\\w+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explanation of the hashtag pattern (thanks GenAI)\n",
    "\n",
    "The regular expression `\\#\\w+` can be broken down into the following components:\n",
    "\n",
    "1. **`\\#`**: \n",
    "   - The backslash (`\\`) is an escape character, which means it is used to treat the hash symbol (`#`) as a literal character rather than a special character in regular expressions. So, this part of the expression matches the `#` symbol literally.\n",
    "\n",
    "2. **`\\w+`**: \n",
    "   - `\\w` is a shorthand character class that matches any \"word\" character. Specifically, it matches:\n",
    "     - Any letter (uppercase or lowercase),\n",
    "     - Any digit (0-9),\n",
    "     - The underscore (`_`).\n",
    "   - The `+` following `\\w` means \"one or more\" of the preceding character class. So, `\\w+` will match one or more word characters.\n",
    "\n",
    "#### In summary:\n",
    "The regular expression `\\#\\w+` matches any string that starts with a `#` symbol, followed by one or more word characters (letters, digits, or underscores).\n",
    "\n",
    "Example matches:\n",
    "- `#hello`\n",
    "- `#123`\n",
    "- `#word_example`\n",
    "\n",
    "This pattern could be used to match hashtags or identifiers that start with `#` followed by alphanumeric characters or underscores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting hashtags to a separate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the code for extracting a hashtag in a function so we can easily re-use it\n",
    "def extract_hashtags(text):\n",
    "    # make sure the input is a string\n",
    "    text = str(text)\n",
    "\n",
    "    # make and return a list of all found hashtags\n",
    "    hashtags = re.findall(hashtag_pattern, text)\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try the pattern on the description we found earlier\n",
    "description = nodes.iloc[0]['author.description']\n",
    "print(extract_hashtags(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have a way to extract hashtags, let's do so for our entire data\n",
    "# we search the author.description column, and make a new column called hashtags with the results\n",
    "nodes['hashtags'] = nodes['author.description'].apply(extract_hashtags)\n",
    "\n",
    "# display the first few rows of hashtags, what stands out?\n",
    "print(nodes['hashtags'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original amount of users: 47404\n",
      "amount of users using hashtags: 7269\n"
     ]
    }
   ],
   "source": [
    "# let's say we are only interested in users with hashtags in their description\n",
    "#first, filter the data\n",
    "\n",
    "hashtag_users = nodes[nodes['hashtags'].str.len() != 0]\n",
    "\n",
    "# only selecting hashtag users has a big cost: we ignore a large number of users\n",
    "print('original amount of users:', len(nodes))\n",
    "print('amount of users using hashtags:', len(hashtag_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting hashtags\n",
    "Now that we have extracted the hashtags, let's see if we can detect some patterns in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, make a flat list of all hashtags\n",
    "# .explode(column) makes a separate row for each hashtags if a single user has more than one\n",
    "flat_hashtags = hashtag_users.explode('hashtags')['hashtags']\n",
    "\n",
    "# now count the occurence of each hashtag\n",
    "flat_hashtags.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing modularity classes\n",
    "Remember the modularity classes we generated in Gephi?\n",
    "\n",
    "We can see if users clustered in different classes prefer different hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# first, get the two biggest classes\n",
    "classes_counts = hashtag_users['modularity_class'].value_counts()\n",
    "print(classes_counts)\n",
    "\n",
    "first_class = classes_counts.index[0]\n",
    "second_class = classes_counts.index[1]\n",
    "\n",
    "print('largest class:', first_class)\n",
    "print('second largest class:', second_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the counting of hashtags for each of the clusters\n",
    "\n",
    "largest_cluster = hashtag_users[hashtag_users['modularity_class'] == first_class]\n",
    "second_cluster = hashtag_users[hashtag_users['modularity_class'] == second_class]\n",
    "\n",
    "largest_cluster_hashtags = largest_cluster.explode('hashtags')['hashtags'].value_counts()\n",
    "second_cluster_hashtags = second_cluster.explode('hashtags')['hashtags'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the hashtags for the two largest clusters\n",
    "For the example data, there is a clear difference in hashtags! We could even identify the clusters based on their hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(largest_cluster_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(second_cluster_hashtags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
